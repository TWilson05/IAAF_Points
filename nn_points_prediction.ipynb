{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20f76787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "event_info = json.load(open(\"2025_fit_params.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bf6f3133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43503, 5), (43503,))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the datasets\n",
    "\n",
    "def time_to_seconds(time_str):\n",
    "    parts = time_str.split(':')\n",
    "    seconds = float(parts[-1])\n",
    "    for i, part in enumerate(reversed(parts[:-1])):\n",
    "        seconds += int(part) * 60 ** (i+1)\n",
    "    if '.' not in time_str:\n",
    "        return seconds - 0.5\n",
    "    else:\n",
    "        return seconds - 0.005\n",
    "\n",
    "points_table = json.load(open(\"2025_points_table.json\", \"r\"))\n",
    "points = np.array(points_table[\"Points\"], dtype=float) + 0.5\n",
    "\n",
    "def get_data(gender, event):\n",
    "    times = np.array(points_table[gender][event]['Scores'])\n",
    "    times = np.array([time_to_seconds(t) if t != \"-\" else np.nan for t in times])\n",
    "    # curve fitting\n",
    "    x_data = np.log(times[~np.isnan(times)])\n",
    "    y_data = points[~np.isnan(times)]\n",
    "    attributes = np.ones((x_data.shape[0],4))\n",
    "    attributes[:,0] = np.log(points_table[gender][event]['Distance'])\n",
    "    attributes[:,1] = np.log(times[~np.isnan(times)] / points_table[gender][event]['Distance'])\n",
    "    if gender != 'Women':\n",
    "        attributes[:,2] = 0\n",
    "    if points_table[gender][event]['Surface'] != 'road':\n",
    "        attributes[:,3] = 0\n",
    "    # if points_table[gender][event]['Surface'] != 'shorttrack':\n",
    "        # attributes[:,4] = 0\n",
    "    # if points_table[gender][event]['Category'] != 'Racewalk':\n",
    "        # attributes[:,5] = 0\n",
    "    x_data = np.concatenate([x_data.reshape(-1,1), attributes], axis=1)\n",
    "    return x_data, y_data\n",
    "\n",
    "fit_params = {\"Men\": {},\n",
    "              \"Women\": {}}\n",
    "\n",
    "xx = []\n",
    "yy = []\n",
    "for gender in fit_params.keys():\n",
    "    for event in points_table[gender].keys():\n",
    "        # if points_table[gender][event]['Category'] in ['Sprints', 'Middle Distance', 'Long Distance']:\n",
    "        if points_table[gender][event]['Category'] in ['Racewalk']:\n",
    "        # if points_table[gender][event]['Category'] in ['Middle Distance', 'Long Distance', 'Racewalk']:\n",
    "            data = get_data(gender, event)\n",
    "            xx.append(data[0])\n",
    "            yy.append(data[1])\n",
    "xx = np.vstack(xx)\n",
    "yy = np.concatenate(yy)\n",
    "xx.shape, yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f18a3c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler_X = StandardScaler()\n",
    "X_numeric = xx[:,:3]\n",
    "X_binary = xx[:,3:]\n",
    "X_numeric_scaled = scaler_X.fit_transform(X_numeric)\n",
    "X_scaled = np.concatenate([X_numeric_scaled, X_binary], axis=1)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(yy.reshape(-1, 1))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.05, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "94ed6b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the neural network\n",
    "\n",
    "class PointsNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(5, 128),  # 5 inputs\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)   # 1 output: points (scaled)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = PointsNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d63a7bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 1.0264\n",
      "Epoch 100 | Loss: 0.0008\n",
      "Epoch 200 | Loss: 0.0004\n",
      "Epoch 300 | Loss: 0.0022\n",
      "Epoch 400 | Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "n_epochs = 500\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_pred = model(X_train_tensor)\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch} | Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "96d8767a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted points: 847.25\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "time = '20:42.38'\n",
    "distance = 5\n",
    "time = '13:22.02'\n",
    "distance = 3\n",
    "# time = '6:41.42'\n",
    "# distance = 1.5\n",
    "gender = 0\n",
    "road = True\n",
    "shorttrack = False\n",
    "racewalk = False\n",
    "\n",
    "def prepare_event(time_str, distance):\n",
    "    parts = time_str.split(':')\n",
    "    seconds = float(parts[-1])\n",
    "    for i, part in enumerate(reversed(parts[:-1])):\n",
    "        seconds += int(part) * 60 ** (i+1)\n",
    "    return np.log(seconds), np.log(distance), np.log(seconds/distance)\n",
    "\n",
    "t, d, p = prepare_event(time, distance)\n",
    "\n",
    "# new_sample = np.array([[t, d, p, gender, road, shorttrack, racewalk]])  # time, distance, gender, road, shorttrack\n",
    "new_sample = np.array([[t, d, p, gender, road]])\n",
    "new_sample_scaled = np.concatenate([scaler_X.transform(new_sample[:,:3]),new_sample[:,3:]], axis=1)\n",
    "new_sample_tensor = torch.tensor(new_sample_scaled, dtype=torch.float32)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction_scaled = model(new_sample_tensor)\n",
    "    prediction_points = scaler_y.inverse_transform(prediction_scaled.numpy())\n",
    "\n",
    "print(f\"Predicted points: {prediction_points[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de798961",
   "metadata": {},
   "source": [
    "Train an ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3018b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_model(X_train_tensor, y_train_tensor, n_epochs=1500, lr=0.001):\n",
    "    model = PointsNet()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_train_tensor)\n",
    "        loss = criterion(y_pred, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a60e4861",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_size = 5\n",
    "ensemble_models = []\n",
    "lrs = np.linspace(0.001, 0.01, ensemble_size)\n",
    "\n",
    "for i in range(ensemble_size):\n",
    "    model = train_single_model(X_train_tensor, y_train_tensor)\n",
    "    ensemble_models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a1f52baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals\n",
    "# Step 1: Get ensemble predictions\n",
    "ensemble_preds = np.mean([model(X_train_tensor).detach().numpy() for model in ensemble_models], axis=0)\n",
    "\n",
    "# Step 2: Fit residual model\n",
    "residuals = y_train_tensor.numpy() - ensemble_preds\n",
    "residual_model = train_single_model(X_train_tensor, torch.tensor(residuals, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c0ce47c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_ensemble(models, sample_tensor, residuals=True):\n",
    "    preds = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = model(sample_tensor)\n",
    "            preds.append(pred.numpy())\n",
    "            pred_res = 0\n",
    "            if residuals:\n",
    "                pred_res = residual_model(sample_tensor).numpy()\n",
    "    avg_pred_scaled = np.mean(preds, axis=0) + pred_res\n",
    "    return scaler_y.inverse_transform(avg_pred_scaled.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "cc16040e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble predicted points: 1307.87\n"
     ]
    }
   ],
   "source": [
    "time = '20:42.38'\n",
    "distance = 5\n",
    "time = '13:22.02'\n",
    "distance = 3\n",
    "time = '6:41.42'\n",
    "distance = 1.5\n",
    "time = '5:24'\n",
    "distance = 1.609\n",
    "gender = 0\n",
    "road = False\n",
    "\n",
    "def prepare_event(time_str, distance):\n",
    "    parts = time_str.split(':')\n",
    "    seconds = float(parts[-1])\n",
    "    for i, part in enumerate(reversed(parts[:-1])):\n",
    "        seconds += int(part) * 60 ** (i+1)\n",
    "    return np.log(seconds), np.log(distance), np.log(seconds/distance)\n",
    "\n",
    "t, d, p = prepare_event(time, distance)\n",
    "\n",
    "# Construct the input as before\n",
    "new_sample = np.array([[t, d, p, gender, road]])  # shape: (1, 5)\n",
    "new_sample_scaled = np.concatenate([\n",
    "    scaler_X.transform(new_sample[:, :3]),  # only scale t, d, p\n",
    "    new_sample[:, 3:]                      # leave binary inputs as-is\n",
    "], axis=1)\n",
    "new_sample_tensor = torch.tensor(new_sample_scaled, dtype=torch.float32)\n",
    "\n",
    "# Predict using ensemble\n",
    "final_prediction = predict_with_ensemble(ensemble_models, new_sample_tensor, residuals=True)\n",
    "print(f\"Ensemble predicted points: {final_prediction[0][0]:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
